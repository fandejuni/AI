\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lecture-rl}
\citation{lecture-rl2}
\citation{intro-rl}
\citation{qlearning}
\citation{lecture-rl}
\citation{lecture-rl2}
\citation{intro-rl}
\citation{sarsa}
\citation{lecture-rl}
\citation{lecture-rl2}
\citation{intro-rl}
\citation{intro-rl}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background and Related Work}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Reinforcement Learning}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}1}Learning}{1}{subsubsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}2}Exploitation vs. Exploration}{1}{subsubsection.2.1.2}}
\newlabel{eq:MAP}{{1}{1}{Exploitation vs. Exploration}{equation.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}The Environment}{1}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}The Agent}{1}{section.4}}
\newlabel{rl_agent}{{\unhbox \voidb@x \hbox {IV-A}}{1}{The Reinforcement Learning Agent}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}The Reinforcement Learning Agent}{1}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}The Minimax Agent}{2}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Discussion}{2}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Performance of your Agent in your Environment}{2}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-A}1}Performance of Learning}{2}{figure.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The learning curve of the RL agent against a random one.}}{2}{figure.1}}
\newlabel{learning_curve_against_random}{{1}{2}{The learning curve of the RL agent against a random one}{figure.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-A}2}Performance of the agents}{2}{subsubsection.5.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Results of the games.}}{2}{table.1}}
\newlabel{comparative_table}{{I}{2}{Results of the games}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Performance of your Agent in the ALife Environment}{2}{subsection.5.2}}
\citation{rl_agent}
\bibcite{lecture-rl}{1}
\bibcite{lecture-rl2}{2}
\bibcite{qlearning}{3}
\bibcite{sarsa}{4}
\bibcite{intro-rl}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Distribution of the proportion of the size of the \emph  {RL} agent for the $776$ games ended after $1000$ iterations.}}{3}{figure.2}}
\newlabel{histo_size}{{2}{3}{Distribution of the proportion of the size of the \emph {RL} agent for the $776$ games ended after $1000$ iterations}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion and Future Work}{3}{section.6}}
\@writefile{toc}{\contentsline {section}{References}{3}{section*.1}}
